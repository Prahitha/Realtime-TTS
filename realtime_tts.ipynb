{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### This implementation provides real-time text-to-speech streaming with character alignment\n",
        "Design goal: Create a production-ready TTS service that can handle various edge cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdkTZiyMY2Py",
        "outputId": "5cdc9267-2722-4846-e01f-9a42c6bb3654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
            "Cloning into 'Kokoro-82M'...\n",
            "remote: Enumerating objects: 421, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 421 (delta 18), reused 0 (delta 0), pack-reused 391 (from 1)\u001b[K\n",
            "Receiving objects: 100% (421/421), 1.83 MiB | 9.11 MiB/s, done.\n",
            "Resolving deltas: 100% (239/239), done.\n",
            "Filtering content: 100% (61/61), 344.32 MiB | 26.70 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "# Install kokoro\n",
        "!pip install -q kokoro soundfile\n",
        "!git clone https://huggingface.co/hexgrad/Kokoro-82M\n",
        "\n",
        "# Install espeak, used for out-of-dictionary fallback\n",
        "!apt-get -qq -y install espeak-ng > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wnzhGatyZC7Z"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import websockets\n",
        "import json\n",
        "import base64\n",
        "import numpy as np\n",
        "import time\n",
        "import re\n",
        "import unicodedata\n",
        "import threading\n",
        "import concurrent.futures\n",
        "from typing import List, Dict, Optional, Tuple, AsyncGenerator, Union\n",
        "from dataclasses import dataclass\n",
        "import logging\n",
        "from io import BytesIO\n",
        "import soundfile as sf\n",
        "import types\n",
        "from collections.abc import Iterator\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-0pD7yT6ZJE8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/opt/homebrew/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        }
      ],
      "source": [
        "# Configure logging for debugging and monitoring production issues\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Import Kokoro TTS (assuming it's installed)\n",
        "try:\n",
        "    from kokoro import KPipeline\n",
        "except ImportError:\n",
        "    logger.error(\"Kokoro TTS not found. Please install it first.\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ep4xeqcFZMFf"
      },
      "outputs": [],
      "source": [
        "# Character weighting for alignment heuristics\n",
        "# These weights are based on phonetic duration research - vowels typically last longer\n",
        "# than consonants, and punctuation creates natural pauses in speech\n",
        "_VOWELS = set(list(\"aeiouAEIOU\"))\n",
        "_PUNCT = set(list(\",.;:!?\\\"'()[]{}\"))\n",
        "_SPACE = set([\" \", \"\\t\", \"\\n\"])\n",
        "\n",
        "def _char_weight(c: str) -> float:\n",
        "    \"\"\"Calculate relative duration weight for a character.\n",
        "\n",
        "    This heuristic approach provides reasonable character timing without\n",
        "    requiring expensive neural alignment models. Based on linguistic research:\n",
        "    - Vowels are typically held longer in speech\n",
        "    - Punctuation creates natural pauses\n",
        "    - Consonants have baseline duration\n",
        "    \"\"\"\n",
        "    if c in _SPACE: return 0.55\n",
        "    if c in _PUNCT: return 0.65\n",
        "    if c in _VOWELS: return 1.25\n",
        "    return 1.0\n",
        "\n",
        "def alignment_for_text(text: str, total_ms: float) -> Dict[str, List[float]]:\n",
        "    \"\"\"Generate heuristic character timing for given text.\n",
        "\n",
        "    This function distributes the total audio duration across characters\n",
        "    based on their phonetic weights. While not as accurate as neural models,\n",
        "    it provides good enough timing for most applications and is much faster.\n",
        "    \n",
        "    Args:\n",
        "        text: The text that was synthesized\n",
        "        total_ms: Total duration of the audio in milliseconds\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary with character-level timing information\n",
        "    \"\"\"\n",
        "\n",
        "    if not text:\n",
        "        return {\"chars\": [], \"char_start_times_ms\": [], \"char_durations_ms\": []}\n",
        "\n",
        "    chars = list(text)\n",
        "    # Calculate weights for each character based on phonetic properties\n",
        "    weights = np.array([_char_weight(c) for c in chars], dtype=np.float64)\n",
        "    W = float(np.sum(weights))\n",
        "\n",
        "    # Handle edge case where all weights are zero (shouldn't happen in practice)\n",
        "    if W <= 0:\n",
        "        weights = np.ones(len(chars), dtype=np.float64)\n",
        "        W = float(len(chars))\n",
        "\n",
        "    # Distribute total duration proportionally based on weights\n",
        "    durations = (weights / W) * float(total_ms)\n",
        "    # Calculate start times by cumulative sum (each character starts when previous ends)\n",
        "    starts = np.concatenate([[0.0], np.cumsum(durations)[:-1]])\n",
        "\n",
        "    return {\n",
        "        \"chars\": chars,\n",
        "        \"char_start_times_ms\": np.round(starts, 3).tolist(),\n",
        "        \"char_durations_ms\": np.round(durations, 3).tolist(),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MClD4sx1ZREU"
      },
      "outputs": [],
      "source": [
        "def _safe_to_numpy(x, target_dtype=np.float32) -> np.ndarray:\n",
        "    \"\"\"Safely convert various types to numpy array.\n",
        "    \n",
        "    This function handles the complexity of different TTS output formats.\n",
        "    Kokoro TTS (and other engines) may return various formats:\n",
        "    - Raw numpy arrays\n",
        "    - PyTorch tensors (need CPU conversion)\n",
        "    - Bytes (PCM data)\n",
        "    - Lists of chunks\n",
        "    - Multi-dimensional arrays (stereo -> mono conversion)\n",
        "    \n",
        "    The robust handling prevents crashes when TTS engines change their output format.\n",
        "    \"\"\"\n",
        "    if x is None:\n",
        "        return np.array([], dtype=target_dtype)\n",
        "\n",
        "    # Handle PyTorch tensors - detach from compute graph and move to CPU\n",
        "    if hasattr(x, \"detach\"):\n",
        "        x = x.detach()\n",
        "    if hasattr(x, \"cpu\"):\n",
        "        x = x.cpu()\n",
        "    if hasattr(x, \"numpy\"):\n",
        "        x = x.numpy()\n",
        "\n",
        "    # Handle raw PCM bytes (common in audio processing)\n",
        "    if isinstance(x, (bytes, bytearray, memoryview)):\n",
        "        # Convert 16-bit PCM to float32 in [-1, 1] range\n",
        "        return np.frombuffer(x, dtype=np.int16).astype(target_dtype) / 32768.0\n",
        "\n",
        "    # Convert to numpy with error handling\n",
        "    try:\n",
        "        arr = np.asarray(x, dtype=target_dtype)\n",
        "    except (ValueError, TypeError):\n",
        "        # If conversion fails, try to handle as flatten nested sequences\n",
        "        if hasattr(x, '__iter__') and not isinstance(x, (str, bytes)):\n",
        "            try:\n",
        "                flat_list = []\n",
        "                for item in x:\n",
        "                    sub_arr = _safe_to_numpy(item, target_dtype)\n",
        "                    if sub_arr.size > 0:\n",
        "                        flat_list.extend(sub_arr.flatten())\n",
        "                return np.array(flat_list, dtype=target_dtype) if flat_list else np.array([], dtype=target_dtype)\n",
        "            except:\n",
        "                return np.array([], dtype=target_dtype)\n",
        "        else:\n",
        "            return np.array([], dtype=target_dtype)\n",
        "\n",
        "    # Ensure we have a valid array\n",
        "    if not isinstance(arr, np.ndarray):\n",
        "        return np.array([], dtype=target_dtype)\n",
        "\n",
        "    # Handle multi-dimensional arrays (make mono)\n",
        "    if arr.ndim > 1:\n",
        "        if arr.ndim == 2 and arr.shape[0] in (1, 2) and arr.shape[1] > arr.shape[0]:\n",
        "            # Likely (channels, samples) format\n",
        "            arr = arr.mean(axis=0, dtype=target_dtype)\n",
        "        else:\n",
        "            # Average across last dimension\n",
        "            arr = arr.mean(axis=-1, dtype=target_dtype)\n",
        "\n",
        "    # Clean up any NaN/Inf values\n",
        "    arr = np.nan_to_num(arr, nan=0.0, posinf=1.0, neginf=-1.0)\n",
        "\n",
        "    return arr.astype(target_dtype, copy=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wgKvFHnEZUmF"
      },
      "outputs": [],
      "source": [
        "def _process_kokoro_output(output) -> np.ndarray:\n",
        "    \"\"\"Process Kokoro TTS output into a clean numpy array.\n",
        "    \n",
        "    Kokoro TTS may return different output formats:\n",
        "    - Tuple: (audio_data, sample_rate) \n",
        "    - Dict: {'audio': data, 'sr': sample_rate, ...}\n",
        "    - Generator: streaming chunks of audio\n",
        "    - Raw array: direct audio data\n",
        "    \n",
        "    This function normalizes all these formats into a single numpy array.\n",
        "    The robust handling prevents service crashes when the TTS engine updates.\n",
        "    \"\"\"\n",
        "    if output is None:\n",
        "        return np.array([], dtype=np.float32)\n",
        "\n",
        "    # Handle tuple outputs like (audio, sample_rate)\n",
        "    if isinstance(output, tuple):\n",
        "        # Could be (audio, sr) or (audio, other_info)\n",
        "        audio_data = output[0]\n",
        "    elif isinstance(output, dict):\n",
        "        # Look for common audio keys\n",
        "        for key in ['audio', 'samples', 'waveform', 'data']:\n",
        "            if key in output:\n",
        "                audio_data = output[key]\n",
        "                break\n",
        "        else:\n",
        "            return np.array([], dtype=np.float32)\n",
        "    else:\n",
        "        audio_data = output\n",
        "\n",
        "    # Handle generators and iterators\n",
        "    if isinstance(audio_data, (types.GeneratorType, Iterator)):\n",
        "        chunks = []\n",
        "        try:\n",
        "            for chunk in audio_data:\n",
        "                chunk_array = _safe_to_numpy(chunk)\n",
        "                if chunk_array.size > 0:\n",
        "                    chunks.append(chunk_array)\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error processing generator output: {e}\")\n",
        "\n",
        "        if chunks:\n",
        "            # Ensure all chunks are 1D before concatenating\n",
        "            flat_chunks = []\n",
        "            for chunk in chunks:\n",
        "                flat_chunk = chunk.flatten()\n",
        "                if flat_chunk.size > 0:\n",
        "                    flat_chunks.append(flat_chunk)\n",
        "\n",
        "            return np.concatenate(flat_chunks) if flat_chunks else np.array([], dtype=np.float32)\n",
        "        else:\n",
        "            return np.array([], dtype=np.float32)\n",
        "\n",
        "    # Handle lists and other sequences\n",
        "    if isinstance(audio_data, (list, tuple)):\n",
        "        if len(audio_data) == 0:\n",
        "            return np.array([], dtype=np.float32)\n",
        "\n",
        "        # Try to process as list of chunks\n",
        "        chunks = []\n",
        "        for item in audio_data:\n",
        "            chunk_array = _safe_to_numpy(item)\n",
        "            if chunk_array.size > 0:\n",
        "                chunks.append(chunk_array.flatten())\n",
        "\n",
        "        if chunks:\n",
        "            return np.concatenate(chunks)\n",
        "        else:\n",
        "            # Fallback: try to convert the whole list\n",
        "            return _safe_to_numpy(audio_data)\n",
        "\n",
        "    # Direct conversion\n",
        "    return _safe_to_numpy(audio_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uL7HEKWZZXXq"
      },
      "outputs": [],
      "source": [
        "def audio_to_pcm16_base64(samples: np.ndarray, sr: int) -> str:\n",
        "    \"\"\"Convert numpy audio to 44.1kHz 16-bit PCM Base64.\n",
        "    \n",
        "    This standardizes all audio to the format expected by web browsers:\n",
        "    - 44.1kHz sample rate (CD quality, widely supported)\n",
        "    - 16-bit PCM (good quality/size balance)\n",
        "    - Base64 encoding for JSON transport\n",
        "    \n",
        "    The resampling uses linear interpolation which is fast and adequate\n",
        "    for TTS applications (higher quality methods like sinc would be slower).\n",
        "    \"\"\"\n",
        "    if samples is None or samples.size == 0:\n",
        "        return \"\"\n",
        "\n",
        "    # Ensure 1D array\n",
        "    samples = samples.flatten()\n",
        "\n",
        "    # Resample to 44.1kHz if needed\n",
        "    target_sr = 44100 # Standard web audio sample rate\n",
        "    if sr != target_sr and samples.size > 0:\n",
        "        ratio = target_sr / float(sr)\n",
        "        target_len = max(1, int(round(len(samples) * ratio)))\n",
        "\n",
        "        if len(samples) > 1:\n",
        "            # Simple linear interpolation for resampling\n",
        "            # More sophisticated methods (like sinc) would be slower\n",
        "            old_indices = np.linspace(0, len(samples) - 1, len(samples))\n",
        "            new_indices = np.linspace(0, len(samples) - 1, target_len)\n",
        "            samples = np.interp(new_indices, old_indices, samples)\n",
        "\n",
        "    # Convert to 16-bit PCM (clip to prevent overflow)\n",
        "    samples = np.clip(samples, -1.0, 1.0) # Ensure samples are in valid range\n",
        "    pcm16 = (samples * 32767.0).astype(np.int16).tobytes()\n",
        "    return base64.b64encode(pcm16).decode('ascii')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "j4B7ZLLsZZ8c"
      },
      "outputs": [],
      "source": [
        "class MathNotationProcessor:\n",
        "    \"\"\"Processes mathematical notation for TTS.\n",
        "    \n",
        "    This class converts LaTeX mathematical expressions into speakable text.\n",
        "    Mathematical notation is common in educational and scientific content,\n",
        "    but TTS engines can't pronounce symbols like ∑ or ∫ correctly.\n",
        "    \n",
        "    The processor handles:\n",
        "    - Common operators (times, divided by, etc.)\n",
        "    - Greek letters (alpha, beta, etc.) \n",
        "    - Fractions, square roots, exponents\n",
        "    - Proper handling of minus signs (unary vs binary)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, unary_minus_word=\"negative\", binary_minus_word=\"minus\"):\n",
        "        \"\"\"Initialize with customizable minus sign pronunciation.\n",
        "        \n",
        "        Different contexts require different minus sign pronunciations:\n",
        "        - Unary: \"-5\" should be \"negative five\"\n",
        "        - Binary: \"7 - 3\" should be \"seven minus three\"\n",
        "        \"\"\"\n",
        "        self.unary_minus_word = unary_minus_word\n",
        "        self.binary_minus_word = binary_minus_word\n",
        "        self.math_symbols = {\n",
        "            r'\\\\times': ' times ',\n",
        "            r'\\\\cdot': ' dot ',\n",
        "            r'\\\\div': ' divided by ',\n",
        "            r'\\\\pm': ' plus or minus ',\n",
        "            r'\\\\mp': ' minus or plus ',\n",
        "            r'\\\\leq': ' less than or equal to ',\n",
        "            r'\\\\geq': ' greater than or equal to ',\n",
        "            r'\\\\neq': ' not equal to ',\n",
        "            r'\\\\approx': ' approximately equal to ',\n",
        "            r'\\\\equiv': ' equivalent to ',\n",
        "            r'\\\\infty': ' infinity ',\n",
        "            r'\\\\sum': ' sum ',\n",
        "            r'\\\\prod': ' product ',\n",
        "            r'\\\\int': ' integral ',\n",
        "            r'\\\\partial': ' partial ',\n",
        "            r'\\\\nabla': ' nabla ',\n",
        "            r'\\\\alpha': ' alpha ',\n",
        "            r'\\\\beta': ' beta ',\n",
        "            r'\\\\gamma': ' gamma ',\n",
        "            r'\\\\delta': ' delta ',\n",
        "            r'\\\\epsilon': ' epsilon ',\n",
        "            r'\\\\theta': ' theta ',\n",
        "            r'\\\\lambda': ' lambda ',\n",
        "            r'\\\\mu': ' mu ',\n",
        "            r'\\\\pi': ' pi ',\n",
        "            r'\\\\sigma': ' sigma ',\n",
        "            r'\\\\phi': ' phi ',\n",
        "            r'\\\\psi': ' psi ',\n",
        "            r'\\\\omega': ' omega ',\n",
        "            r'\\\\sqrt': ' square root ',\n",
        "        }\n",
        "\n",
        "        # Precompiled regex patterns for better performance\n",
        "        # Math expressions can be inline \\(...\\) or display \\[...\\]\n",
        "        self._re_inline = re.compile(r'\\\\\\((.*?)\\\\\\)', re.DOTALL)\n",
        "        self._re_display = re.compile(r'\\\\\\[(.*?)\\\\\\]', re.DOTALL)\n",
        "        self._re_left_right = re.compile(r'\\\\left|\\\\right')\n",
        "        self._re_frac = re.compile(r'\\\\frac\\{([^{}]+)\\}\\{([^{}]+)\\}')\n",
        "        self._re_sqrt = re.compile(r'\\\\sqrt\\{([^{}]+)\\}')\n",
        "        self._re_pow_simple = re.compile(r'\\^(\\w)')\n",
        "        self._re_pow_braced = re.compile(r'\\^\\{([^}]+)\\}')\n",
        "        self._re_sub_simple = re.compile(r'_(\\w)')\n",
        "        self._re_sub_braced = re.compile(r'_\\{([^}]+)\\}')\n",
        "        self._re_unary_minus = re.compile(r'(^|[\\(\\[\\{\\s])-(?=\\s*[\\w(])')\n",
        "        self._re_binary_minus = re.compile(r'\\s-\\s|(?<=\\w)-(?=\\s)|(?<=\\s)-(?=\\w)')\n",
        "        self._re_num_letter = re.compile(r'(?<=\\d)(?=[A-Za-z])')\n",
        "        self._re_letter_num = re.compile(r'(?<=[A-Za-z])(?=\\d)')\n",
        "        self._re_multi_space = re.compile(r'\\s+')\n",
        "\n",
        "    def process_math_text(self, text: str) -> str:\n",
        "        \"\"\"Process mathematical notation in text.\n",
        "        \n",
        "        Finds LaTeX expressions and converts them to speakable text.\n",
        "        Handles both inline \\(...\\) and display \\[...\\] math modes.\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return text\n",
        "\n",
        "        # Process inline math: \\(expression\\)\n",
        "        text = self._re_inline.sub(self._process_math_expression, text)\n",
        "        # Process display math: \\[expression\\]\n",
        "        text = self._re_display.sub(self._process_math_expression, text)\n",
        "        return text\n",
        "\n",
        "    def _process_math_expression(self, match) -> str:\n",
        "        \"\"\"Process a single math expression.\n",
        "        \n",
        "        Converts LaTeX math syntax to natural language.\n",
        "        Order of operations matters - process complex structures first,\n",
        "        then simple substitutions.\n",
        "        \"\"\"\n",
        "        expr = match.group(1)\n",
        "\n",
        "        # Remove sizing delimiters\n",
        "        expr = self._re_left_right.sub('', expr)\n",
        "\n",
        "        # Replace symbols\n",
        "        for symbol, replacement in self.math_symbols.items():\n",
        "            expr = re.sub(symbol, replacement, expr)\n",
        "\n",
        "        # Handle fractions (with nesting support)\n",
        "        prev = None\n",
        "        while prev != expr:\n",
        "            prev = expr\n",
        "            expr = self._re_frac.sub(r'\\1 over \\2', expr)\n",
        "\n",
        "        # Handle square roots\n",
        "        expr = self._re_sqrt.sub(r'square root of \\1', expr)\n",
        "\n",
        "        # Handle exponents\n",
        "        expr = self._re_pow_braced.sub(r' to the power of \\1', expr)\n",
        "        expr = self._re_pow_simple.sub(r' to the power of \\1', expr)\n",
        "\n",
        "        # Handle subscripts\n",
        "        expr = self._re_sub_braced.sub(r' sub \\1', expr)\n",
        "        expr = self._re_sub_simple.sub(r' sub \\1', expr)\n",
        "\n",
        "        # Handle minus signs\n",
        "        expr = self._re_unary_minus.sub(rf'\\1{self.unary_minus_word} ', expr)\n",
        "        expr = self._re_binary_minus.sub(f' {self.binary_minus_word} ', expr)\n",
        "\n",
        "        # Add spacing for readability\n",
        "        expr = self._re_num_letter.sub(' ', expr)\n",
        "        expr = self._re_letter_num.sub(' ', expr)\n",
        "\n",
        "        # Clean up spacing\n",
        "        expr = self._re_multi_space.sub(' ', expr).strip()\n",
        "        return f\" {expr} \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VxPbwsHJZhKg"
      },
      "outputs": [],
      "source": [
        "def sanitize_text(text: str) -> str:\n",
        "    \"\"\"Sanitize text for TTS processing.\n",
        "    \n",
        "    TTS engines work best with clean, normalized text.\n",
        "    This function handles common issues:\n",
        "    - Unicode normalization (different encodings of same character)\n",
        "    - Smart quotes -> ASCII quotes  \n",
        "    - Various dash types -> ASCII dash\n",
        "    - Non-breaking spaces -> regular spaces\n",
        "    - Mathematical symbols -> words\n",
        "    \n",
        "    The goal is consistent, speakable text that won't confuse the TTS engine.\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return text\n",
        "\n",
        "    # Unicode normalization - convert visually similar characters to standard form\n",
        "    # NFKC handles things like smart quotes, em dashes, etc.\n",
        "    text = unicodedata.normalize('NFKC', text)\n",
        "\n",
        "    # Replace problematic unicode characters with ASCII equivalents\n",
        "    # These mappings handle the most common text encoding issues\n",
        "    replacements = {\n",
        "        0x201C: '\"', 0x201D: '\"', 0x2018: \"'\", 0x2019: \"'\",\n",
        "        0x2013: '-', 0x2014: '-', 0x2212: '-',\n",
        "        0x00A0: ' ', 0x202F: ' ', 0x2007: ' ', 0x2009: ' ',\n",
        "        0x200A: ' ', 0x2000: ' ', 0x2001: ' ', 0x2002: ' ',\n",
        "        0x2003: ' ', 0x2004: ' ', 0x2005: ' ', 0x2006: ' ',\n",
        "        0x2028: ' ', 0x2029: ' '\n",
        "    }\n",
        "    text = text.translate(replacements)\n",
        "\n",
        "    # Collapse whitespace\n",
        "    text = re.sub(r'[\\r\\n\\t]+', ' ', text)\n",
        "\n",
        "    # Replace math symbols with words\n",
        "    text = text.translate(str.maketrans({\n",
        "        '/': ' slash ', '=': ' equals ', '+': ' plus ',\n",
        "        '*': ' times ', '%': ' percent ', '&': ' and ',\n",
        "        '|': ' or ', '\\\\': ' '\n",
        "    }))\n",
        "\n",
        "    # Clean up spacing\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0jaahH3fZkRy"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class TTSChunk:\n",
        "    \"\"\"Represents a chunk of TTS output.\n",
        "    \n",
        "    Each chunk contains:\n",
        "    - audio_b64: Base64-encoded PCM audio data\n",
        "    - alignment: Character-level timing information\n",
        "    - text: The original text that generated this audio\n",
        "    \n",
        "    This structure allows the client to synchronize audio playback\n",
        "    with text highlighting for better user experience.\n",
        "    \"\"\"\n",
        "    audio_b64: str\n",
        "    alignment: Dict[str, List[float]]\n",
        "    text: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fypXCBBoZm0i"
      },
      "outputs": [],
      "source": [
        "class WebSocketTTSService:\n",
        "    \"\"\"Main WebSocket TTS Service.\n",
        "    \n",
        "    This class implements a streaming TTS service compatible with ElevenLabs API.\n",
        "    Key design decisions:\n",
        "    \n",
        "    1. Streaming architecture: Process text as it arrives, don't wait for complete input\n",
        "    2. Sentence boundary detection: Generate audio at natural speech boundaries  \n",
        "    3. Error resilience: Continue operation even if individual chunks fail\n",
        "    4. Memory efficiency: Process audio in chunks to handle long texts\n",
        "    5. Protocol compatibility: Follow ElevenLabs WebSocket message format\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, host=\"localhost\", port=8765, voice=\"af_heart\", use_ngrok=False):\n",
        "        \"\"\"Initialize the TTS service.\n",
        "        \n",
        "        Args:\n",
        "            host: Server bind address (0.0.0.0 allows external connections)\n",
        "            port: Server port (8765 is common for WebSocket services)\n",
        "            voice: Voice model identifier for Kokoro TTS\n",
        "        \"\"\"\n",
        "        self.host = host\n",
        "        self.port = port\n",
        "        self.voice = voice\n",
        "        self.use_ngrok = use_ngrok\n",
        "        self.ngrok_tunnel = None\n",
        "        self.math_processor = MathNotationProcessor()\n",
        "\n",
        "        # Initialize Kokoro pipeline\n",
        "        logger.info(\"Initializing Kokoro TTS pipeline...\")\n",
        "        try:\n",
        "            self.pipeline = KPipeline(lang_code='a')\n",
        "            self.default_sr = getattr(self.pipeline, \"sample_rate\", 24000)\n",
        "            logger.info(\"TTS pipeline ready!\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to initialize Kokoro pipeline: {e}\")\n",
        "            raise\n",
        "\n",
        "    async def handle_client(self, websocket):\n",
        "        \"\"\"Handle a WebSocket client connection.\n",
        "        \n",
        "        This implements the ElevenLabs-compatible protocol:\n",
        "        1. Client sends \" \" (space) to initiate\n",
        "        2. Client sends text chunks with flush=false\n",
        "        3. Server responds with audio chunks\n",
        "        4. Client sends \"\" with flush=false to disconnect\n",
        "        \n",
        "        The text buffer accumulates partial sentences and generates audio\n",
        "        at natural boundaries (sentence endings) for optimal speech quality.\n",
        "        \"\"\"\n",
        "        client_id = f\"{websocket.remote_address[0]}:{websocket.remote_address[1]}\"\n",
        "        logger.info(f\"Client connected: {client_id}\")\n",
        "\n",
        "        text_buffer = \"\"\n",
        "\n",
        "        try:\n",
        "            async for message in websocket:\n",
        "                try:\n",
        "                    data = json.loads(message)\n",
        "                    text = data.get(\"text\", \"\")\n",
        "                    flush = data.get(\"flush\", False)\n",
        "\n",
        "                    logger.debug(f\"Received: text='{text}', flush={flush}\")\n",
        "\n",
        "                    # Handle protocol: first message has single space, last has empty string\n",
        "                    if text == \" \" and not text_buffer:\n",
        "                        # First message - just acknowledge\n",
        "                        continue\n",
        "                    elif text == \"\" and not flush:\n",
        "                        # Final message - close connection\n",
        "                        logger.info(f\"Client {client_id} requested disconnect\")\n",
        "                        break\n",
        "\n",
        "                    # Add text to buffer\n",
        "                    if text and text != \" \":\n",
        "                        processed_text = self.math_processor.process_math_text(text)\n",
        "                        processed_text = sanitize_text(processed_text)\n",
        "                        text_buffer += processed_text\n",
        "\n",
        "                    # Check if we should generate audio\n",
        "                    should_generate = flush or self._should_generate_audio(text_buffer)\n",
        "\n",
        "                    if should_generate and text_buffer.strip():\n",
        "                        # Get text to generate\n",
        "                        if flush:\n",
        "                            generate_text = text_buffer.strip()\n",
        "                            text_buffer = \"\"\n",
        "                        else:\n",
        "                            generate_text = self._extract_complete_sentences(text_buffer)\n",
        "                            text_buffer = text_buffer[len(generate_text):].strip()\n",
        "\n",
        "                        if generate_text:\n",
        "                            # Generate and stream audio\n",
        "                            async for chunk in self._generate_audio_stream(generate_text):\n",
        "                                if chunk.audio_b64:  # Only send if we have valid audio\n",
        "                                    response = {\n",
        "                                        \"audio\": chunk.audio_b64,\n",
        "                                        \"alignment\": chunk.alignment\n",
        "                                    }\n",
        "                                    await websocket.send(json.dumps(response))\n",
        "\n",
        "                except json.JSONDecodeError:\n",
        "                    logger.error(f\"Invalid JSON from client {client_id}\")\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error processing message from {client_id}: {e}\")\n",
        "\n",
        "        except websockets.exceptions.ConnectionClosed:\n",
        "            logger.info(f\"Client {client_id} disconnected\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error handling client {client_id}: {e}\")\n",
        "        finally:\n",
        "            logger.info(f\"Connection closed for client {client_id}\")\n",
        "\n",
        "    def _should_generate_audio(self, text_buffer: str) -> bool:\n",
        "        \"\"\"Determine if we should generate audio from current buffer.\n",
        "        \n",
        "        This implements smart streaming logic:\n",
        "        - Generate immediately when we have complete sentences (for natural speech)\n",
        "        - Generate when buffer gets too long (prevent memory issues and reduce latency)\n",
        "        - Don't generate for empty/whitespace-only buffers\n",
        "        \n",
        "        The goal is to balance speech naturalness with responsiveness.\n",
        "        \"\"\"\n",
        "        if not text_buffer.strip():\n",
        "            return False\n",
        "\n",
        "        # Generate on sentence boundaries\n",
        "        sentence_endings = ['.', '!', '?', '\\n']\n",
        "        if any(ending in text_buffer for ending in sentence_endings):\n",
        "            return True\n",
        "\n",
        "        # Generate if buffer gets too long\n",
        "        return len(text_buffer) > 100\n",
        "\n",
        "    def _extract_complete_sentences(self, text_buffer: str) -> str:\n",
        "        \"\"\"Extract complete sentences from buffer.\n",
        "        \n",
        "        This function finds natural breaking points in text to generate\n",
        "        coherent speech. It prioritizes sentence boundaries, but falls back\n",
        "        to word boundaries for very long sentences.\n",
        "        \n",
        "        Returns the text that should be synthesized now, leaving the\n",
        "        remainder in the buffer for future processing.\n",
        "        \"\"\"\n",
        "        sentence_endings = ['.', '!', '?', '\\n']\n",
        "\n",
        "        for ending in sentence_endings:\n",
        "            if ending in text_buffer:\n",
        "                idx = text_buffer.rfind(ending) + 1\n",
        "                return text_buffer[:idx].strip()\n",
        "\n",
        "        # If no sentence ending and buffer is long, split at word boundary\n",
        "        # This prevents very long sentences from causing latency issues\n",
        "        if len(text_buffer) > 100:\n",
        "            words = text_buffer.split()\n",
        "            if len(words) > 5:\n",
        "                mid_point = len(words) // 2\n",
        "                return ' '.join(words[:mid_point])\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    async def _generate_audio_stream(self, text: str) -> AsyncGenerator[TTSChunk, None]:\n",
        "        \"\"\"Generate audio stream for given text.\n",
        "        \n",
        "        This function implements the core streaming logic:\n",
        "        1. Split text into optimal chunks for TTS processing\n",
        "        2. Generate audio for each chunk\n",
        "        3. Yield results as they're ready (don't wait for all chunks)\n",
        "        \n",
        "        The streaming approach reduces perceived latency and allows\n",
        "        for real-time playback of long texts.\n",
        "        \"\"\"\n",
        "        if not text.strip():\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            # Split text into manageable chunks\n",
        "            # Smaller chunks = lower latency, but may affect speech quality\n",
        "            # 50 characters is a good balance for most TTS engines\n",
        "            chunks = self._split_text_smart(text, max_len=50)\n",
        "\n",
        "            # Generate audio for each chunk\n",
        "            for chunk_text in chunks:\n",
        "                if not chunk_text.strip():\n",
        "                    continue\n",
        "\n",
        "                start_time = time.time()\n",
        "\n",
        "                # Generate audio using Kokoro\n",
        "                try:\n",
        "                    audio, sr = await self._generate_kokoro_audio(chunk_text)\n",
        "\n",
        "                    if audio is not None and audio.size > 0:\n",
        "                        # Convert to required format\n",
        "                        audio_b64 = audio_to_pcm16_base64(audio, sr)\n",
        "\n",
        "                        # Calculate audio duration and generate alignment\n",
        "                        audio_duration_ms = (len(audio) / sr) * 1000\n",
        "                        alignment = alignment_for_text(chunk_text, audio_duration_ms)\n",
        "\n",
        "                        generation_time = time.time() - start_time\n",
        "                        logger.info(f\"Generated audio for '{chunk_text[:30]}...' in {generation_time:.3f}s\")\n",
        "\n",
        "                        yield TTSChunk(\n",
        "                            audio_b64=audio_b64,\n",
        "                            alignment=alignment,\n",
        "                            text=chunk_text\n",
        "                        )\n",
        "                    else:\n",
        "                        logger.warning(f\"No audio generated for text: '{chunk_text[:30]}...'\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error generating audio for chunk '{chunk_text[:30]}...': {e}\")\n",
        "                    continue\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating audio stream: {e}\")\n",
        "\n",
        "    async def _generate_kokoro_audio(self, text: str) -> Tuple[np.ndarray, int]:\n",
        "        \"\"\"Generate audio using Kokoro TTS with improved error handling.\n",
        "        \n",
        "        This function wraps the TTS engine call with:\n",
        "        1. Thread pool execution (TTS engines often block)\n",
        "        2. Robust output format handling\n",
        "        3. Sample rate detection\n",
        "        4. Error recovery\n",
        "        \n",
        "        The async wrapper prevents TTS generation from blocking\n",
        "        the WebSocket event loop, allowing multiple clients.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Run TTS in thread pool to avoid blocking event loop\n",
        "            loop = asyncio.get_event_loop()\n",
        "            with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "                result = await loop.run_in_executor(\n",
        "                    executor, lambda: self.pipeline(text, voice=self.voice)\n",
        "                )\n",
        "\n",
        "            # Get sample rate\n",
        "            sr = int(getattr(self.pipeline, \"sample_rate\", getattr(self, \"default_sr\", 24000)))\n",
        "\n",
        "            # Process the output safely\n",
        "            audio = _process_kokoro_output(result)\n",
        "\n",
        "            # If we got a tuple with sample rate info, use it\n",
        "            if isinstance(result, tuple) and len(result) >= 2 and isinstance(result[1], (int, float)):\n",
        "                sr = int(result[1])\n",
        "            elif isinstance(result, dict) and 'sr' in result:\n",
        "                sr = int(result['sr'])\n",
        "            elif isinstance(result, dict) and 'sample_rate' in result:\n",
        "                sr = int(result['sample_rate'])\n",
        "\n",
        "            if audio.size == 0:\n",
        "                logger.warning(f\"Empty audio generated for text: '{text[:30]}...'\")\n",
        "                return np.array([], dtype=np.float32), sr\n",
        "\n",
        "            logger.debug(f\"Generated audio shape: {audio.shape}, sr: {sr}\")\n",
        "            return audio, sr\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Kokoro TTS error for text '{text[:30]}...': {e}\")\n",
        "            return np.array([], dtype=np.float32), int(getattr(self, \"default_sr\", 24000))\n",
        "\n",
        "    def _split_text_smart(self, text: str, max_len: int = 50) -> List[str]:\n",
        "        \"\"\"Smart text splitting for optimal TTS processing.\n",
        "        \n",
        "        This function splits long text into chunks that:\n",
        "        1. Respect sentence boundaries (most important for speech quality)\n",
        "        2. Respect phrase boundaries (commas, semicolons)\n",
        "        3. Stay under maximum length (for processing efficiency)\n",
        "        \n",
        "        The hierarchical splitting ensures natural-sounding speech\n",
        "        even when dealing with very long input texts.\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return []\n",
        "\n",
        "        # Split on sentence boundaries first\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
        "        chunks = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            if len(sentence) <= max_len:\n",
        "                chunks.append(sentence)\n",
        "            else:\n",
        "                # Split long sentences at phrase boundaries\n",
        "                phrases = re.split(r'(?<=[,;:])\\s+', sentence)\n",
        "                current_chunk = \"\"\n",
        "\n",
        "                for phrase in phrases:\n",
        "                    if len(current_chunk + \" \" + phrase) <= max_len:\n",
        "                        current_chunk = (current_chunk + \" \" + phrase).strip()\n",
        "                    else:\n",
        "                        if current_chunk:\n",
        "                            chunks.append(current_chunk)\n",
        "                        current_chunk = phrase\n",
        "\n",
        "                if current_chunk:\n",
        "                    chunks.append(current_chunk)\n",
        "\n",
        "        return [chunk.strip() for chunk in chunks if chunk.strip()]\n",
        "\n",
        "    async def start_server(self):\n",
        "        \"\"\"Start the WebSocket server.\n",
        "        \n",
        "        This creates a persistent WebSocket server that can handle\n",
        "        multiple simultaneous clients. Each client connection is\n",
        "        handled in its own async task.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Starting TTS WebSocket server on {self.host}:{self.port}\")\n",
        "        \n",
        "        # Create WebSocket server with connection handler\n",
        "        async with websockets.serve(self.handle_client, self.host, self.port):\n",
        "            logger.info(f\"TTS WebSocket server running on ws://{self.host}:{self.port}\")\n",
        "            # Run forever (until interrupted)\n",
        "            await asyncio.Future()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZVT7KqrrZrRZ"
      },
      "outputs": [],
      "source": [
        "# WebSocket Client for Testing\n",
        "class TTSWebSocketClient:\n",
        "    \"\"\"Test client for the TTS WebSocket service.\n",
        "    \n",
        "    This class provides a programmatic interface for testing\n",
        "    the TTS service. It implements the same protocol as web clients\n",
        "    and can be used for automated testing or integration testing.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, uri=\"ws://localhost:8765\"):\n",
        "        self.uri = uri\n",
        "        self.websocket = None\n",
        "\n",
        "    async def connect(self):\n",
        "        \"\"\"Connect to the TTS service\"\"\"\n",
        "        self.websocket = await websockets.connect(self.uri)\n",
        "        logger.info(f\"Connected to {self.uri}\")\n",
        "\n",
        "    async def send_text_chunk(self, text: str, flush: bool = False):\n",
        "        \"\"\"Send a text chunk to the service.\n",
        "        \n",
        "        Args:\n",
        "            text: Text to synthesize\n",
        "            flush: Whether to flush any buffered text\n",
        "        \"\"\"\n",
        "        message = {\"text\": text, \"flush\": flush}\n",
        "        await self.websocket.send(json.dumps(message))\n",
        "        logger.debug(f\"Sent: {message}\")\n",
        "\n",
        "    async def receive_audio_chunk(self) -> Optional[Dict]:\n",
        "        \"\"\"Receive an audio chunk from the service.\n",
        "        \n",
        "        Returns:\n",
        "            Dictionary with 'audio' and 'alignment' keys, or None if connection closed\n",
        "        \"\"\"\n",
        "        try:\n",
        "            message = await self.websocket.recv()\n",
        "            return json.loads(message)\n",
        "        except websockets.exceptions.ConnectionClosed:\n",
        "            return None\n",
        "\n",
        "    async def disconnect(self):\n",
        "        \"\"\"Disconnect from the service\"\"\"\n",
        "        await self.send_text_chunk(\"\", False)  # Send empty string to close\n",
        "        await self.websocket.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JhnMrUu5ZuC5"
      },
      "outputs": [],
      "source": [
        "# Main execution\n",
        "async def main():\n",
        "    \"\"\"Main function to run the TTS service.\n",
        "    \n",
        "    Can be run as either server or test client based on command line arguments.\n",
        "    \"\"\"\n",
        "    import sys\n",
        "    \n",
        "    if len(sys.argv) > 1 and sys.argv[1] == \"client\":\n",
        "        # Run test client\n",
        "        await run_test_client()\n",
        "    else:\n",
        "        # Run server\n",
        "        service = WebSocketTTSService(host=\"0.0.0.0\", port=8765)\n",
        "        await service.start_server()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SOIfBCePZwCJ"
      },
      "outputs": [],
      "source": [
        "async def run_test_client():\n",
        "    \"\"\"Run a test client.\n",
        "    \n",
        "    This demonstrates the full protocol flow:\n",
        "    1. Connect and send initial space\n",
        "    2. Send text chunks \n",
        "    3. Receive and process audio chunks\n",
        "    4. Disconnect properly\n",
        "    \"\"\"\n",
        "    client = TTSWebSocketClient(\"ws://localhost:8765\")\n",
        "    await client.connect()\n",
        "    \n",
        "    # Send initial space (protocol requirement)\n",
        "    await client.send_text_chunk(\" \")\n",
        "    \n",
        "    # Test text with mathematical notation\n",
        "    test_texts = [\n",
        "        \"Hello, this is a test of the TTS system. \",\n",
        "        \"The equation \\\\(a^2 + b^2 = c^2\\\\) is the Pythagorean theorem. \",\n",
        "        \"The derivative of \\\\(e^x\\\\) is \\\\(\\\\frac{d}{dx} e^x = e^x\\\\). \",\n",
        "        \"\"  # Final empty string to close\n",
        "    ]\n",
        "    \n",
        "    # Start receiving audio in background task\n",
        "    async def receive_audio():\n",
        "        while True:\n",
        "            chunk = await client.receive_audio_chunk()\n",
        "            if chunk is None:\n",
        "                break\n",
        "            logger.info(f\"Received audio chunk: {len(chunk['audio'])} bytes, \"\n",
        "                       f\"{len(chunk['alignment']['chars'])} characters, \"\n",
        "                       f\"Text: '{chunk['alignment']['chars'][0:20]}...'\")\n",
        "\n",
        "    receive_task = asyncio.create_task(receive_audio())\n",
        "    \n",
        "    # Send text chunks with realistic typing delays\n",
        "    for i, text in enumerate(test_texts[:-1]):\n",
        "        await client.send_text_chunk(text)\n",
        "        await asyncio.sleep(1)  # Simulate typing delay\n",
        "    \n",
        "    # Send final disconnect message\n",
        "    await client.send_text_chunk(\"\", False)\n",
        "    \n",
        "    # Wait for all audio to be received\n",
        "    await receive_task\n",
        "    await client.disconnect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
